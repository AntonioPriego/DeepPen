\chapter{Red Neuronal}
{\color{red} lo que debes contar aquí es lo que se hay
que saber para poder hacer un sistema con redes neuronales usando
TinyML, qué hay que instalar, qué partes de la biblioteca vas a usar
y por qué, cómo se genera la base de datos de entrenamiento, cómo
de entrena, etc. De hecho, lo mismo tienes que partir el desarrollo en
varios capítulos, según la cantidad de cosas que tengas que saber.
Para que te hagas una idea, en los capítulos dedicados al desarrollo
tienes que contar qué has hecho como si se lo estuvieras contando a
un amiguete de cervezas. indicando qué cosas son las importantes, por
qué hay que hacerlas, etc., pero sin detalles técnicos. Los detalles
técnicos estarán en los apéndices y loe irás referenciando cuando
sea oportuno, para que el que tenga curiosidad, lo mire, aunque el
texto debe estar redactado para entender la idea general sin necesidad
de ver los apéndices. }

\section{Diseño}
El diseño de un modelo es determinante para que se desenvuelva apropiadamente
a la hora de realizar su función. Por más que se dote al modelo durante el
entrenamiento de un gran volumen de datos, será vano si el diseño no está enfocado
a la labor que tiene que desempeñar. Por lo tanto, para el diseño de este modelo,
se han estudiado otros muchos de clasificación de formas y procesamiento de imagen; la
mayoría hacían uso del célebre \textit{MNIST}: una base de datos que cuenta con
60.000 imágenes de entrenamiento y 10.000 de testeo, es un gran dataset de imágenes
de dígitos.\newline
Para examinar con mayor profundidad la experimentación respecto al diseño del modelo,
observesé '\textbf{Experimentación con el modelo}' en el Apéndice.

{\color{migris} Cada uno de los modelos con los que se ha experimentado, son
pequeñas iteraciones o pequeños cambios respecto del modelo base. Creado a partir
del estudio de otros modelos para tareas parecidas.\\

\textbf{MODELO BASE}\\
Cuenta con una estructura de \textit{Keras}, \textit{Sequential}\textsuperscript{\cite{sequential}};
gracias a esta utilidad, es posible añadir capas al modelo de forma cómoda, además
de algunas funciones para el entrenamiento.

Las capas son las siguientes:
\begin{itemize}
    \itemsep0em 
    \item Rescaling\textsuperscript{\cite{rescaling}}: Como resultado de esta capa,
    se consigue reescalar o normalizar
    los valores de los inputs, en nuestro caso las imágenes. Con esto definimos
    una escala uniforme y es un procedimiento típico en procesamiento de imagen:
    \textit{image normalization}, donde se normalizará el valor de los píxeles
    de las imágenes a una escala [0,1].
    \item Conv2D\textsuperscript{\cite{conv2d}}: Capa para procesamiento convolucional,
    es la capa que realmente
    procesará dentro del modelo. Se crea un kernel que convoluciona con la entrada
    de la capa. Se define la capa en base ciertos parámetros que determinarán su
    funcionamiento y complejidad, siendo en nuestro caso los parámetros:
    \begin{itemize}
        \itemsep0em 
        \item filters: el número de filtros de salida de la convolución.
        \item kernel\_size: el tamaño de ventana de convolución, cuando se
        especifica un solo número, se interpreta una ventana cuadrada de ese
        tamaño.
        \item strides: define el tamaño de los tramos de salto de la ventana
        de convolución.
        \item input\_shape: establecer el tamaño de la entrada. En nuestro caso
        imágenes de 32x32.
    \end{itemize}
    \item BatchNormalization\textsuperscript{\cite{bnorm}}: Normaliza sus entradas por lotes.
    Aplica transformaciones
    que conservan la media de la salida cercana a 0 y la desviación estándar a 1.
    \item Activation\textsuperscript{\cite{activation}}: aplica una función de activación a una salida. Las funciones de
    activación son las que arbitran la activación de las neuronas de la red neuronal
    y por ello, repercute en su salida. Existen diversas
    funciones de activación, como lo son \textit{rectified linear unit(relu)},
    \textit{sigmoid}, \textit{softmax}(función de distribución de probabilidad), etc.
    \item Dropout\textsuperscript{\cite{dropout}}: Capa que introduce cierta entropía, de forma que se descarta
    la contribución de ciertas neuronas de forma estadística. Se suelen implementar
    para soslayar el \textit{overfitting}.
    \item GlobalAveragePooling2D\textsuperscript{\cite{gap2d}}: Esta capa tomará un
    tensor de dimensión $x*y*z$ y
    calculando el valor medio de los valores $x$ e $y$, producirá una salida basada en
    $z$ elementos.
    \item Dense\textsuperscript{\cite{dense}}: Es una capa común de red neuronal,
    solo que está \textit{densamente}
    conectada, es decir, cada neurona de esta capa está conectada a todas las neuronas
    de la capa anterior. Se usa, como es nuestro caso, en redes clasificatorias.
\end{itemize}

Nuestro modelo base va a contar especificamente con 3 bloques de capas de convolución,
normalización, activación y dropout.\newline
¿Por qué estas capas? Esencialmente se debe a que el aporte de cada una de ellas,
complementa al procesamiento convolucional irremplazable. Por tanto, la capa
\textit{Conv2D} es la de procesamiento, tras esta, se normaliza la salida con la capa
\textit{BatchNormalization}, lo cual garantiza una mayor estabilidad y eficiencia
en el proceso de aprendizaje. Se define como función de activación, \textit{relu}; no
por otra cosa que porque es la más utilizada, la que mejor funciona para prácticamente
todas las labores sin tener que profundizar en el estudio del mismo y por su bajo
coste computacional; destacable debido a la naturaleza del dispositivo en el que
se ejecutará la red neuronal. Y por último la capa de \textit{Dropout} ayuda
con el overfitting, un problema que se ha podido experimentar debido a que es una red
neuronal de complejidad menor.\newline
En cada bloque lo único que varía es el número de filtros de la capa de convolución,
duplicándose en cada uno.
Previo a los 3 bloques citados, hay una capa de \textit{Rescaling}, que va a servir
meramente para normalizar los valores los píxeles de las imágenes a una escala [0,1].

Y por último, tras los 3 bloques, una capa \textit{GlobalAveragePooling2D} por simple
coherencia estructural debido a que reduce la dimensionalidad pero conserva la mayor
parte de información relevante(utilizada en la práctica totalidad de \textit{CNN}s), otra capa \textit{Dropout} por el mismo motivo que en los
bloques y finalmente la popular capa \textit{Dense} para obtener un output clasificatorio.
}

\section{Implementación}
\subsection{Preparativos}
Previo al diseño, se han de instalar ciertas dependencias y definir
algunos parámetros asistentes para el código. La mayoría de dependencias
son para trabajar con estructuras de datos en python, interfaces con el OS, o
librerías para \textit{TensorFlow} y \textit{Keras}.\newline
\textit{Keras}\textsuperscript{\cite{Aurelien,keras}} será la API de alto nivel que se usará
para trabajar con las capas del modelo y el estudio de los resultados del entrenamiento.\newline
Otra dependencia imprescindible es \textit{xxd}.
\begin{teoria}{Uso de \textit{xxd}\textsuperscript{\cite{tf-xxd}}}
    \color{mitexto}
    Es esencial contar con \textit{xxd}, esto se debe a que la mayoría de
    microcontroladores no tienen soporte para sistema de archivos nativo.\newline
    Con \textit{xxd} obtenemos el modelo en formato matriz de chars directamente
    compatible con \textbf{C/C++} e integrable en cualquier microcontrolador.\newline
    Es recomendable establecer esta matriz como constante por cuestiones de
    eficiencia en el acceso a memoria.
\end{teoria}

Tambien necesitaremos el dataset para el entrenamiento del modelo, que se irá
actualizando a medida que se toman más muestras y que se podrá descargar
desde el \textit{Google Drive} institucional. Se acompaña la descarga de una comprobación
de existencia del fichero descargado para concluir esta sección.\newline
Con el dataset descargado, se almacenan los trazos en un array, en el que
cada elemento del array será un trazo; de momento de todos los labels.\newline
Los trazos en este momento están cargados como conjunto de coordenadas que
conforman, unas seguidas de otras, un recorrido; presumiblemente una letra.
Pero como ya es sabido, nuestro modelo necesita como entrada imágenes; por lo que
el siguiente paso es rasterizar los trazos para producir una imagen.\newline
Al igual que en el sketch, se hará uso de la función de rasterización programada
por \textit{Pete Warden}\textsuperscript{\cite{petewardenmw}}. Definidas las funciones de
rasterización, es posible rasterizar todos los trazos y destinarlos a los distintos 
propósitos respecto al modelo.
\begin{teoria}{Uso del dataset en \textit{Deep Learing}(1)\textsuperscript{\cite{Andreas}}}
    \color{mitexto}
    Los tres datasets que se usan para \textit{Deep Learing} son:
    \begin{itemize}
        \itemsep0em
        \item \textbf{Validation}\\
        {\small En \textit{Deep Learning} se usan datos de validación para corroborar
        durante el entrenamiento, que el ajuste se está dando de forma óptima.\newline
        Dilatando un poco más esta sencilla explicación, el \textit{validation dataset}
        es un conjunto de datos imperativamente distinto del \textit{training dataset},
        que sirve para estimar la eficacia de la red en tiempo de entrenamiento.\newline
        En general se suele usar la validación para hacer estudios del ajuste del modelo,
        para evitar sobreajustes(\textit{overfitting}) y subajustes(\textit{underfitting}).}
        \begin{teoria}{\textit{Overfitting} y \textit{Underfitting}}
            \color{mitexto}
            \begin{itemize}
                \item \textbf{\textit{Overfitting}}\\
                {\small Es un fenómeno que se da cuando el modelo reconoce peculiaridades
                demasiado específicas como distintivo para la evaluación. Estas
                peculiaridades no serían los rasgos o características que constituyen
                a los elementos que estudiados y por lo tanto se produce un
                sobreajuste; un ajuste por encima de lo óptimo.} 
                \item \textbf{\textit{Underfitting}}\\
                {\small Término análogo y opuesto al anterior, el ajuste se
                presentaría laxo y falto de rigurosidad; ajuste por debajo de
                lo óptimo.} 
            \end{itemize}\end{teoria}
    \end{itemize}
\end{teoria}
\begin{teoria}{Uso del dataset en \textit{Deep Learing}(2)\textsuperscript{\cite{Andreas}}}
    \color{mitexto}
    \begin{itemize}
        \itemsep0em 
        \item \textbf{Training}\\
        {\small Este dataset es el más simple de entender por mera inmediación
        semántica. Es el conjunto de datos que se utiliza en tiempo de entrenamiento
        para balancear los pesos de las capas. En cada iteración de entrenamiento,
        se calcula la pérdida con los datos de entrenamiento introducidos y
        se da el ajuste de pesos en base a la pérdida. Esto supone que, cada vez la
        pérdida sea menor y generalmente la eficacia, o en términos más comunes a este
        ámbito, la \textit{precisión}(\textit{accuracy}), sea mayor.}
        \item \textbf{Test}\\
        {\small El conjunto de datos que se utilizará posterior al entrenamiento, para
        validar la efectividad del entrenamiento.\newline
        Es el dataset con el que se pone a prueba el modelo entrenado.}
    \end{itemize}
\end{teoria}
Se utilizará el mismo conjunto de datos aleatoriamente distribuido para cada
uno de los tres dataset. Cada dataset contará con un porcentaje del conjunto de datos
total. Estos porcentajes serán estudiados pero a priori no suponen extrema relevancia
más allá de que el de entrenamiento debe ser ampliamente mayor. Ha sido fijado un
10\% para test, otro 10\% para validación y el restante 80\% para entrenamiento.\newline
Las imágenes del dataset ocuparán 32x32 píxeles. Este es otro parámentro que puede
ser estudiado, no obstante, estas dimensiones han sido las que han arrojado mejores
resultados de forma homogénea. \newline Presentando mejores resultados el reconocimiento
de letras complejas(como la 'k'), a medida que las dimensiones aumentan. Y extrapolando
el mismo comportamiento a letras simples(como la 'c'), a razón de una menor resolución.

{\color{red}Para ampliar: \url{https://www.v7labs.com/blog/train-validation-test-set}}
{\color{red}Hablar de bloque 'PREPARE DATASETS'}

\subsection{Entrenamiento}
{\color{red} Entrenamiento}\\

Documentación:
\url{https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d}

\subsection{Testeo}
{\color{red} Testeo}\\

\subsection{Transformación a modelo cuantizado}
{\color{red} Transformación a modelo quantico y por qué}\\

\subsection{Comparación de modelos}
{\color{red} Comparación modelos}\\

\subsection{Integración en el sketch}
{\color{red} Obtención de labels}\\
{\color{red} Obtención del modelo integrable en C/C++}\\
{\color{red} Modelo cuantizado por eficiencia y por ahorrar memoria, no
por carencia de FPU}\\